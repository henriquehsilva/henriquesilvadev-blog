---
title: "Dia #1: Aprendendo a Correr"
description: ""
pubDate: "Jan 07 2025"
badge: "#instrucional"
tags: ["TREINO DE CORRIDA", "TREINO DE FOR√áA", "SONO", "DIETA"]
slug: "dia-1-aprendendo-a-correr"
heroImage: ""
---

<h3>06h - Iniciando o Dia</h3>

<p style="text-align: justify">
    Acordei hoje as 06h ap√≥s uma boa noite de sono.
</p>

!['Registro SONO 070125'](https://henriquesilva.dev/registro-sono-070125.png "Registro SONO 070125")

<p style="text-align: justify">
    Tomei ioimbina com cafe√≠na em jejum para otimizar a absor√ß√£o e os resultados. Depois, levei a Milk üê∂ ao espa√ßo pet e, em seguida, me arrumei para o treino de corrida, conforme a planilha de hoje.
</p>

<h3>06h:30min - Treino de Corrida</h3>

1. Aquecer 10' Z1 - Muito f√°cil (08:00 a 07:30/km) 7,5 a 8km/h completar entre 1,25 e 1,35km.
2. Repetir 6X :  Correr 5' Z2 - Pouca ofeg√¢ncia (07:30 a 07:04/km) 8 a 8,5km/h    completar entre 0,65 e 0,7km
3. Caminhar 1'

<h4>Resultados do Treino</h4>

!['Treino Corrida 070125'](https://henriquesilva.dev/treino-corrida-070125.png "Treino Corrida 070125")

<h3>07h:40min - Pesagem</h3>

Ao chegar em casa, decidi fazer uma checagem de peso e fiquei muito feliz com os resultados.

!['Pesagem 070125'](https://henriquesilva.dev/checagem-peso-070125.png "Pesagem 070125")


- O modelo deve ser capaz de prever com precis√£o a sobreviv√™ncia dos passageiros com uma taxa de acerto superior a X%.
- A an√°lise explorat√≥ria de dados deve fornecer insights significativos sobre os fatores que influenciaram a sobreviv√™ncia dos passageiros.
- O c√≥digo deve ser bem documentado, modular e replic√°vel.
- O relat√≥rio final deve resumir claramente os resultados obtidos, incluindo as limita√ß√µes do modelo e poss√≠veis melhorias futuras.

<p style="text-align: justify">
    Ao seguir a metodologia CRISP-DM (Cross-Industry Standard Process for Data Mining), podemos abordar sistematicamente esses requisitos para garantir o sucesso do projeto Titanic - Machine Learning from Disaster e fornecer resultados valiosos para a melhoria da seguran√ßa mar√≠tima.
</p>

<h3>Fase 1: Entendimento do Neg√≥cio</h3>

<p style="text-align: justify">
    As necessidades do neg√≥cio para o projeto Titanic - Machine Learning from Disaster envolvem a cria√ß√£o de um modelo preditivo capaz de determinar a probabilidade de sobreviv√™ncia dos passageiros do Titanic com base em uma variedade de caracter√≠sticas. Essa previs√£o √© vital para compreender melhor os fatores que influenciaram as chances de sobreviv√™ncia dos passageiros e, consequentemente, auxiliar na formula√ß√£o de pol√≠ticas de seguran√ßa mar√≠tima mais eficazes.
</p>

<h3>Fase 2: Prepara√ß√£o de Dados/An√°lise Explorat√≥ria de Dados (EDA)</h3>

<p style="text-align: justify">
    Baixar o conjunto de dados de <a href="https://www.kaggle.com/competitions/titanic/data" target="_blank">Titanic - Machine Learning from Disaster Data</a> e salvar em local. Abrir o Jupyter Notebook e importar as bibliotecas necess√°rias. Para carregar o conjunto de dados.
</p>

``` python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns

file_train='./data/train.csv'
file_test='./data/test.csv'

seed = 69
np.random.seed(seed)

train_df = pd.read_csv(file_train,index_col='PassengerId')
test_df = pd.read_csv(file_test,index_col='PassengerId')
```

```python
train_df.columns.values
```
!['Show columns'](https://henriquesilva.dev/show_columns.png "Show columns")

```python
train_df.shape
```
!['Show shape'](https://henriquesilva.dev/shape_titanic.png "Show shape")


```python
train_df.head()
````

!['train_df.head()'](https://henriquesilva.dev/head_titanic.png "train_df.head()")

<p style="text-align: justify">
    Usando Dataframe.info(), sabemos que o conjunto de dados √© composto por 12 colunas e 891 linhas. 5 colunas de dados est√£o na forma de n√∫meros inteiros, 2 colunas de dados est√£o na forma de n√∫meros de ponto flutuante, enquanto o restante est√° na forma de string. Tamb√©m podemos concluir que h√° valores ausentes em 3 colunas [Age, Cabin, Embarked] dos dados.
</p>

```python
train_df.info()
```

!['Dataframe.info()'](https://henriquesilva.dev/df_info.png "Dataframe.info()")


<p style="text-align: justify">
    Para obter uma compreens√£o b√°sica dos dados, podeamos usar fun√ß√£o DataFrame.describe(). Por padr√£o, esta fun√ß√£o retorna estat√≠sticas descritivas para as vari√°veis num√©ricas. No entanto, podemos descobrir as informa√ß√µes dos objetos incluindo include=‚Äôobject‚Äô como par√¢metro.
</p>

```python
train_df.describe()
```

!['Dataframe.describe()'](https://henriquesilva.dev/df_describe.png "Dataframe.describe()")

```python
train_df.isnull().sum()
````

!['Dataframe.isnull().sum()'](https://henriquesilva.dev/isnull.png "Dataframe.isnull().sum()")

```python
def prepare_data(df):
    # Remove colunas n√£o relevantes
    df.drop(['Name', 'Ticket', 'Cabin'], axis = 'columns', inplace = True)

    # Binarizar sexo
    df['Sex'] = df['Sex'].map({'female': 1, 'male': 0}).astype(int)

    # Preencha os dados faltantes: media de [Fare] e [Embarked] com valor mais frequente
    df[['Fare']] = df[['Fare']].fillna(value=df[['Fare']].mean())
    df[['Embarked']] = df[['Embarked']].fillna(value=df['Embarked'].value_counts().idxmax())

    # Converter [Embarked] para "one-hot"
    enbarked_one_hot = pd.get_dummies(df['Embarked'], prefix='Embarked', dtype=int)
    df.drop('Embarked', axis= 'columns', inplace = True)
    df = df.join(enbarked_one_hot)

    # Define index ao [PasseId]
    df.rename_axis(None, axis = 'rows', inplace = True)
    df.rename_axis('PasserId', axis = 'columns', inplace = True)

    return df
````

```python
train_df = prepare_data(train_df)
```

!['Prepare data'](https://henriquesilva.dev/prep_data_titanic.png "Prepare data")

<p style="text-align: justify">
<b>Imputa√ß√£o com base em outras vari√°veis:</b> agrupando os dados por sexo e classe socioecon√¥mica em seguida, calcula a mediana da idade em cada grupo para preencher os valores faltantes.
</p>

```python
def filter_ages_to_sex_and_pclass(sex_id, pclass_id, df):
    df = df[df['Sex'].isin([sex_id])]
    df = df[df['Pclass'].isin([pclass_id])]
    df.loc[:, 'Age'] = round(df['Age'].fillna(value=df['Age'].median()))

    return df
```

```python
df1 = filter_ages_to_sex_and_pclass(1, 1, train_df)
df2 = filter_ages_to_sex_and_pclass(1, 2, train_df)
df3 = filter_ages_to_sex_and_pclass(1, 3, train_df)
df4 = filter_ages_to_sex_and_pclass(0, 1, train_df)
df5 = filter_ages_to_sex_and_pclass(0, 2, train_df)
df6 = filter_ages_to_sex_and_pclass(0, 3, train_df)
```

```python
frames = [df1, df2, df3, df4, df5, df6]
train_df = pd.concat(frames).sort_index()

train_df.info()
```

!['Imputa√ß√£o com base em outras vari√°veis'](https://henriquesilva.dev/info_total.png "Imputa√ß√£o com base em outras vari√°veis")

<h3>Scatterplot Matrix</h3>

```python
sns.set_theme(style = "ticks")
sns.pairplot(train_df, hue = "Survived")
```
!['Scatterplot Matrix'](https://henriquesilva.dev/scatterplot_m_titanic.png "Scatterplot Matrix")

<p style="text-align: justify">
<b>Obs.:</b> Ap√≥s replicar o processo de prepara√ß√£o dos dados em <b>test_df</b> temos: 
</p>

```python
test_df.info()
```

!['Info total test'](https://henriquesilva.dev/info_total_test.png "Info total test")